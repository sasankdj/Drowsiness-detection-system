<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Drowsiness Alert System</title>
  <style>
    @import url('https://fonts.googleapis.com/css2?family=Roboto:wght@400;700&display=swap');
    body, html {
      margin: 0; padding: 0; width: 100%; height: 100%;
      background: linear-gradient(135deg, #4d79ff, #1cd8d2);
      font-family: 'Roboto', sans-serif;
      display: flex; justify-content: center; align-items: center;
      flex-direction: column;
      color: #fff;
      overflow: hidden;
    }
    h1 {
      margin-bottom: 0.1em;
      font-weight: 700;
      text-shadow: 1px 1px 5px rgba(0,0,0,0.2);
    }
    #status {
      font-size: 1.25rem;
      margin-bottom: 1em;
      font-weight: 500;
      text-shadow: 1px 1px 8px rgba(0,0,0,0.25);
    }
    #videoWrapper {
      position: relative;
      width: 640px;
      height: 480px;
      border-radius: 15px;
      overflow: hidden;
      box-shadow: 0 15px 35px rgba(0, 0, 0, 0.3);
      border: 5px solid #fff;
      background: #222;
    }
    video, canvas {
      position: absolute;
      top: 0; left: 0;
      width: 100%;
      height: 100%;
      object-fit: cover;
      border-radius: 15px;
    }
    #alertBtn {
      position: absolute;
      bottom: 20px;
      left: 50%;
      transform: translateX(-50%);
      background-color: #27ae60;
      border: none;
      padding: 15px 40px;
      color: white;
      font-size: 1.25rem;
      font-weight: 700;
      border-radius: 50px;
      cursor: pointer;
      box-shadow: 0 8px 20px rgba(39, 174, 96, 0.6);
      display: none;
      transition: background-color 0.3s ease;
      z-index: 10;
    }
    #alertBtn:hover {
      background-color: #2ecc71;
    }
    #earDisplay {
      position: absolute;
      top: 20px;
      right: 20px;
      background: rgba(0,0,0,0.4);
      padding: 8px 15px;
      border-radius: 12px;
      font-weight: 700;
      font-size: 1rem;
      user-select: none;
      box-shadow: 0 4px 12px rgba(0,0,0,0.3);
    }
    #drowsinessAlert {
      position: absolute;
      top: 20px;
      left: 20px;
      background: rgba(255, 0, 0, 0.8);
      padding: 10px 15px;
      border-radius: 15px;
      font-weight: 900;
      font-size: 1.3rem;
      box-shadow: 0 4px 12px rgba(255,0,0,0.7);
      user-select: none;
      display: none;
      z-index: 10;
    }
  </style>
</head>
<body>
  <h1>Drowsiness Alert System</h1>
  <div id="status">Status: Monitoring</div>
  <div id="videoWrapper">
    <video id="video" autoplay muted playsinline></video>
    <canvas id="overlay"></canvas>
    <button id="alertBtn">I'm Awake</button>
    <div id="earDisplay">EAR: 0.00</div>
    <div id="drowsinessAlert">DROWSINESS ALERT!</div>
  </div>

  <audio id="alarmSound" src="/alarm.mp3" preload="auto"></audio>

  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.21.0/dist/tf.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/facemesh@0.0.4/dist/facemesh.min.js"></script>
  <script>
    const video = document.getElementById('video');
    const canvas = document.getElementById('overlay');
    const ctx = canvas.getContext('2d');
    const alertBtn = document.getElementById('alertBtn');
    const statusDisplay = document.getElementById('status');
    const earDisplay = document.getElementById('earDisplay');
    const drowsinessAlert = document.getElementById('drowsinessAlert');
    const alarmSound = document.getElementById('alarmSound');

    let model = null;
    let alarmOn = false;
    let userConfirmedAwake = false;
    let counter = 0;
    const EAR_THRESHOLD = 0.25;
    const CONSEC_FRAMES = 20;

    // Coordinates for eye landmarks from FaceMesh
    // Left Eye indices approx for TensorFlow FaceMesh: 
    // Upper left eye: [33, 160, 158, 133, 153, 144, 163, 7]
    // For EAR approx using 6 key points from eye [33, 160, 158, 133, 153, 144]
    // Using points similar to Dlib indices but adapted for FaceMesh
    const leftEyeIndices = [33, 160, 158, 133, 153, 144];
    const rightEyeIndices = [362, 385, 387, 263, 373, 380];

    function euclideanDist(a, b) {
      return Math.hypot(a[0] - b[0], a[1] - b[1]);
    }

    // Calculate EAR for an eye given six landmarks
    function eyeAspectRatio(eye) {
      const A = euclideanDist(eye[1], eye[5]);
      const B = euclideanDist(eye[2], eye[4]);
      const C = euclideanDist(eye[0], eye[3]);
      return (A + B) / (2.0 * C);
    }

    alertBtn.onclick = () => {
      userConfirmedAwake = true;
      alarmOn = false;
      drowsinessAlert.style.display = 'none';
      alertBtn.style.display = 'none';
      counter = 0;
      statusDisplay.textContent = 'Status: Monitoring';
      alarmSound.pause();
      alarmSound.currentTime = 0;
    };

    async function setupCamera() {
      if (navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {
        const stream = await navigator.mediaDevices.getUserMedia({
          video: { width: 640, height: 480 },
          audio: false
        });
        video.srcObject = stream;
        return new Promise((resolve) => {
          video.onloadedmetadata = () => {
            resolve(video);
          };
        });
      } else {
        alert('getUserMedia() is not supported by your browser');
      }
    }

    async function loadModel() {
      model = await facemesh.load();
    }

    function drawEyeContours(eye) {
      ctx.strokeStyle = 'lime';
      ctx.lineWidth = 2;
      ctx.beginPath();
      ctx.moveTo(eye[0][0], eye[0][1]);
      for (let i = 1; i < eye.length; i++) {
        ctx.lineTo(eye[i][0], eye[i][1]);
      }
      ctx.closePath();
      ctx.stroke();
    }

    function drawFaceLandmarks(predictions) {
      ctx.clearRect(0, 0, canvas.width, canvas.height);
      for (let pred of predictions) {
        const keypoints = pred.scaledMesh;

        // Left Eye points
        const leftEye = leftEyeIndices.map(i => keypoints[i]);
        // Right Eye points
        const rightEye = rightEyeIndices.map(i => keypoints[i]);

        drawEyeContours(leftEye);
        drawEyeContours(rightEye);
      }
    }

    async function detect() {
      const predictions = await model.estimateFaces(video, false, false);

      if (predictions.length > 0) {
        const keypoints = predictions[0].scaledMesh;

        const leftEye = leftEyeIndices.map(i => keypoints[i]);
        const rightEye = rightEyeIndices.map(i => keypoints[i]);

        const leftEAR = eyeAspectRatio(leftEye);
        const rightEAR = eyeAspectRatio(rightEye);
        const ear = (leftEAR + rightEAR) / 2;

        earDisplay.textContent = `EAR: ${ear.toFixed(2)}`;

        if (ear < EAR_THRESHOLD) {
          counter++;
          if (counter >= CONSEC_FRAMES) {
            if (!alarmOn) {
              alarmOn = true;
              userConfirmedAwake = false;
              alarmSound.loop = true;
              alarmSound.play();
              drowsinessAlert.style.display = 'block';
              alertBtn.style.display = 'block';
              statusDisplay.textContent = 'Status: Drowsiness Alert!';
            }
          }
        } else {
          counter = 0;
          if (!alarmOn) {
            userConfirmedAwake = false;
            drowsinessAlert.style.display = 'none';
            alertBtn.style.display = 'none';
            statusDisplay.textContent = 'Status: Monitoring';
            alarmSound.pause();
            alarmSound.currentTime = 0;
          }
        }

        drawFaceLandmarks(predictions);
      } else {
        // No face detected
        earDisplay.textContent = 'EAR: --';
        ctx.clearRect(0, 0, canvas.width, canvas.height);
        counter = 0;
        if (!alarmOn) {
          userConfirmedAwake = false;
          drowsinessAlert.style.display = 'none';
          alertBtn.style.display = 'none';
          statusDisplay.textContent = 'Status: Face Not Detected';
          alarmSound.pause();
          alarmSound.currentTime = 0;
        }
      }
      requestAnimationFrame(detect);
    }

    async function main() {
      await setupCamera();
      video.play();

      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;

      await loadModel();
      detect();
    }

    main();
  </script>
</body>
</html>

